{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f0850d-b74f-47bf-9a47-9f30f50c594d",
   "metadata": {},
   "source": [
    "## Learn gpt and learn the basics of pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f3d72-c870-43bb-9f20-af364708e35b",
   "metadata": {},
   "source": [
    "reference:\n",
    "+ https://pytorch.org/docs/stable/index.html\n",
    "+ https://github.com/karpathy/nanoGPT/blob/master/model.py\n",
    "+ https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
    "+ https://github.com/rasbt/LLMs-from-scratch\n",
    "+ ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32b5e4-ca28-4870-a654-a2bf7152b7af",
   "metadata": {},
   "source": [
    "purpose:\n",
    "+ build a simple gpt model using pytorch\n",
    "+ build a simple gpt model using simple function in pytroch\n",
    "+ understand the data flow of each module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b867117-fecd-4a79-a3a2-1f312b552b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import inspect\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe603b-7b86-4fec-9f63-89930f18f2f6",
   "metadata": {},
   "source": [
    "## inspect Module\n",
    "The inspect module provides several useful functions to help you get information about live objects, such as modules, classes, methods, functions, tracebacks, frame objects, and code objects. It is primarily used for introspection, which means examining the type or properties of an object at runtime.\n",
    "\n",
    "Key functions in the inspect module include:\n",
    "\n",
    "+ inspect.getmembers(object): Return all the members of an object.\n",
    "+ inspect.signature(callable): Return a Signature object for the given callable.\n",
    "+ inspect.isfunction(object): Return True if the object is a Python function.\n",
    "+ inspect.isclass(object): Return True if the object is a class.\n",
    "+ inspect.getdoc(object): Return the documentation string for an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c6a8d0-2b05-4ec3-87de-8479f3af7c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a, b)\n",
      "This is my function.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "def my_function(a, b):\n",
    "    \"\"\"This is my function.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Get the signature of the function\n",
    "sig = inspect.signature(my_function)\n",
    "print(sig)  # Output: (a, b)\n",
    "\n",
    "# Get the documentation of the function\n",
    "doc = inspect.getdoc(my_function)\n",
    "print(doc)  # Output: This is my function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42eed18-2fd5-4862-99d6-0340d3d96430",
   "metadata": {},
   "source": [
    "## dataclasses Module\n",
    "The dataclasses module provides a decorator and functions for automatically adding special methods to user-defined classes. These methods include __init__, __repr__, __eq__, and others. The main purpose is to reduce boilerplate code when creating classes that primarily store data.\n",
    "\n",
    "A class decorated with @dataclass automatically gets:\n",
    "\n",
    "+ An '__init__' method that initializes the instance variables.\n",
    "+ A '__repr__' method that provides a string representation of the instance.\n",
    "+ An '__eq__' method that allows comparison between instances.\n",
    "+ Additional methods based on the parameters provided to the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ead35d-ad9a-4a32-b19f-2fda8de0512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point(x=1, y=2)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Point:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "# Creating an instance of Point\n",
    "p1 = Point(1, 2)\n",
    "print(p1)  # Output: Point(x=1, y=2)\n",
    "\n",
    "# Comparing instances of Point\n",
    "p2 = Point(1, 2)\n",
    "print(p1 == p2)  # Output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24687239-3818-4f46-ab55-dbc413b27f2a",
   "metadata": {},
   "source": [
    "* can you give me a Example to make me understand the usage of \"__repr__\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8612eb39-30d7-414f-a5b4-1ac9d921329f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(name='Alice', age=30)\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Person(name={self.name!r}, age={self.age!r})\"\n",
    "\n",
    "# Creating an instance of the Person class\n",
    "p = Person(\"Alice\", 30)\n",
    "\n",
    "# Printing the instance\n",
    "print(p)  # Output: Person(name='Alice', age=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756b5fdc-75b0-4da5-bb5d-c35096b28101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4214bd-0b3b-401d-995b-aada57d62b0e",
   "metadata": {},
   "source": [
    "## layerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab69436b-e790-4cdc-bb48-4e63345b7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba9282-966c-4a7a-8a59-69a878da495e",
   "metadata": {},
   "source": [
    "+ The super().__init__() call in the __init__ method of a class that inherits from another class (in this case, nn.Module) is used to initialize the parent class (nn.Module). This ensures that the parent class is properly initialized, setting up any required state or initial configurations defined in the parent class.\n",
    "\n",
    "+ In PyTorch, nn.Module is a base class for all neural network modules, and it includes important initialization steps, such as setting up the internal structures for managing the parameters of the model and handling GPU/CPU transfers. By calling super().__init__(), you make sure that the LayerNorm class properly inherits and initializes these properties and functionalities from nn.Module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383007b-20f6-435c-a061-c5f05a0775f5",
   "metadata": {},
   "source": [
    "+ https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#layernorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ddbfea-ef1c-4b60-9474-ee21ce21cd35",
   "metadata": {},
   "source": [
    "Layer normalization (LayerNorm) is a technique used in deep learning to improve the training and performance of neural networks. It normalizes the inputs across the features for each training example independently, which helps stabilize the learning process and accelerates convergence. Hereâ€™s a mathematical explanation of how LayerNorm works:\n",
    "\n",
    "### Summary of Steps\n",
    "\n",
    "1. **Compute the mean** of the input vector $ \\mathbf{x} $.\n",
    "2. **Compute the variance** of the input vector $ \\mathbf{x} $.\n",
    "3. **Normalize** the input vector $ \\mathbf{x} $ using the computed mean and variance.\n",
    "4. **Scale and shift** the normalized input using learnable parameters $ \\gamma $ and $ \\beta $.\n",
    "\n",
    "### Benefits of LayerNorm\n",
    "\n",
    "- **Stabilizes Training:** By normalizing the inputs to each layer, LayerNorm helps stabilize the training process, especially for deep networks.\n",
    "- **Accelerates Convergence:** Normalization helps the model converge faster by providing more stable gradients.\n",
    "- **Reduces Covariate Shift:** By normalizing across features, LayerNorm reduces internal covariate shift, which is the change in the distribution of network activations due to the updating of parameters.\n",
    "\n",
    "### Comparison with Batch Normalization (BatchNorm)\n",
    "\n",
    "- **Normalization Scope:** BatchNorm normalizes across the batch dimension, whereas LayerNorm normalizes across the feature dimension.\n",
    "- **Application:** BatchNorm is more effective for convolutional neural networks (CNNs) with large batch sizes, while LayerNorm is more suitable for recurrent neural networks (RNNs) and transformers where batch sizes can vary or be small.\n",
    "\n",
    "Understanding LayerNorm mathematically involves recognizing its role in standardizing the inputs to a neural network layer, which in turn helps in achieving stable and efficient training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d29f0-112b-44f9-8c46-7ea25c3358a5",
   "metadata": {},
   "source": [
    "Yes, L1 norm and L2 norm are two common ways to measure the length (or magnitude) of a vector in a vector space. They are widely used in various fields, including machine learning and statistics.\n",
    "\n",
    "### L1 Norm (Manhattan Norm or Taxicab Norm)\n",
    "\n",
    "The L1 norm of a vector $ \\mathbf{x} = [x_1, x_2, \\ldots, x_n] $ is defined as the sum of the absolute values of its components:\n",
    "\n",
    "$\n",
    "\\| \\mathbf{x} \\|_1 = \\sum_{i=1}^n |x_i|\n",
    "$\n",
    "\n",
    "For example, for the vector $ \\mathbf{x} = [1, -2, 3, -4, 5] $:\n",
    "\n",
    "$\n",
    "\\| \\mathbf{x} \\|_1 = |1| + |-2| + |3| + |-4| + |5| = 1 + 2 + 3 + 4 + 5 = 15\n",
    "$\n",
    "\n",
    "### L2 Norm (Euclidean Norm)\n",
    "\n",
    "The L2 norm of a vector $ \\mathbf{x} = [x_1, x_2, \\ldots, x_n] $ is defined as the square root of the sum of the squares of its components:\n",
    "\n",
    "$\n",
    "\\| \\mathbf{x} \\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}\n",
    "$\n",
    "\n",
    "For the same vector $ \\mathbf{x} = [1, -2, 3, -4, 5] $:\n",
    "\n",
    "$\n",
    "\\| \\mathbf{x} \\|_2 = \\sqrt{1^2 + (-2)^2 + 3^2 + (-4)^2 + 5^2} = \\sqrt{1 + 4 + 9 + 16 + 25} = \\sqrt{55} \\approx 7.416\n",
    "$\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **L1 Norm**: Used in Lasso regression, where it encourages sparsity in the model parameters, effectively performing feature selection.\n",
    "- **L2 Norm**: Used in Ridge regression, where it encourages smaller coefficients, helping to prevent overfitting by penalizing large weights.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **L1 Norm**: Sum of absolute values of vector components.\n",
    "- **L2 Norm**: Square root of the sum of the squares of vector components.\n",
    "\n",
    "Both norms are useful in different contexts and have distinct properties that make them suitable for various tasks in machine learning and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d156dd0-a84b-4655-873a-37997e140465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes:\n"
     ]
    }
   ],
   "source": [
    "text = '''First Citizen:\n",
    "We are accounted poor citizens, the patricians good.\n",
    "What authority surfeits on would relieve us: if they\n",
    "would yield us but the superfluity, while it were\n",
    "wholesome, we might guess they relieved us humanely;\n",
    "but they think we are too dear: the leanness that\n",
    "afflicts us, the object of our misery, is as an\n",
    "inventory to particularise their abundance; our\n",
    "sufferance is a gain to them Let us revenge this with\n",
    "our pikes, ere we become rakes:'''\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728d242c-5571-4e10-bff1-664201200212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{':', '\\n', 'k', 'i', ',', 'n', 'h', '.', 'F', ';', 'f', 'm', 'j', 'g', 's', 'z', 'a', 'o', 'C', 'p', 'w', 'u', 'y', 'v', 't', 'W', 'e', 'r', 'L', 'd', ' ', 'c', 'b', 'l'}\n"
     ]
    }
   ],
   "source": [
    "print(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4b4ce9-64eb-4f22-a178-960c7a601a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', ',', '.', ':', ';', 'C', 'F', 'L', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(set(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b10c87-9274-4ad3-8734-bb52eefa25b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "1  \n",
      "2 ,\n",
      "3 .\n",
      "4 :\n",
      "5 ;\n",
      "6 C\n",
      "7 F\n",
      "8 L\n",
      "9 W\n",
      "10 a\n",
      "11 b\n",
      "12 c\n",
      "13 d\n",
      "14 e\n",
      "15 f\n",
      "16 g\n",
      "17 h\n",
      "18 i\n",
      "19 j\n",
      "20 k\n",
      "21 l\n",
      "22 m\n",
      "23 n\n",
      "24 o\n",
      "25 p\n",
      "26 r\n",
      "27 s\n",
      "28 t\n",
      "29 u\n",
      "30 v\n",
      "31 w\n",
      "32 y\n",
      "33 z\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "for i,ch in enumerate(chars):\n",
    "    print(i,ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2aeec65-8e77-4841-bad1-6dbdf64726f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5248,  1044, 11086, 11059])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ix = torch.randint(12315, (4,))\n",
    "print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977dff1d-2161-4829-80fa-8639aa82a02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10390,  2825,  6406,  5501,  4820,  5107,  2540, 10388],\n",
      "        [ 7783,  6997,  6379,  4976, 11672, 10848,  8931,  9748],\n",
      "        [ 9113,  1373,  2486,   742,  2324,  5557,   956,  8499],\n",
      "        [ 3402,  7472,  8843, 10691,  7444,  9004,  4771,  6852]])\n"
     ]
    }
   ],
   "source": [
    "ixx = torch.randint(12315, (4,8))\n",
    "print(ixx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea434d1b-9782-4620-b41b-a4385bf794a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc59ebf-db9a-46e5-809e-e1e2e90d54b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2619,  0.5803,  0.2570, -1.6198,  0.7313],\n",
      "        [-0.6691, -1.0521,  0.3380, -0.1779,  0.6680],\n",
      "        [-0.8905, -1.0465,  0.2469, -0.9095,  0.6921]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820e0e8d-7858-45f5-952a-633240d8d55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c611b4d-415e-4dba-8265-4102148e40c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6540, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32fc7580-96d1-4d8d-b8e8-7395dfdbea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 5])\n",
      "tensor([[[ 0.0556,  0.7931,  0.2027, -1.1361,  1.4996],\n",
      "         [ 0.7243, -1.0727, -0.0048, -0.7183, -0.1111],\n",
      "         [ 0.5431, -0.5410,  0.3666, -0.8849, -0.4974],\n",
      "         [ 1.3834, -1.7518,  1.3320, -1.0032, -0.1557]],\n",
      "\n",
      "        [[ 0.0234,  2.2345,  0.0224,  0.4388, -0.4750],\n",
      "         [ 0.0817, -0.2610, -0.7862,  0.2321, -0.3828],\n",
      "         [ 0.3017,  0.3296, -0.6282,  0.3463, -0.2611],\n",
      "         [-1.8314, -0.8343, -1.2071, -1.0810,  0.9788]],\n",
      "\n",
      "        [[-0.4080, -1.2915, -0.4471, -1.7200, -0.9816],\n",
      "         [ 2.1752, -0.9490,  0.4909,  1.1006,  0.7446],\n",
      "         [ 0.8315, -0.7812,  0.5920,  0.1139,  0.7367],\n",
      "         [ 1.1277, -1.5654, -1.3464, -0.5767,  0.7914]],\n",
      "\n",
      "        [[-0.4262, -2.2725, -1.3849,  0.8259,  0.2521],\n",
      "         [ 0.1539,  0.3614,  0.1212, -0.8539,  0.4816],\n",
      "         [ 0.1144, -0.3812,  0.3434, -0.4478, -0.2321],\n",
      "         [-0.5238, -1.3684, -2.2022,  0.1606,  0.7356]],\n",
      "\n",
      "        [[ 0.4162, -1.7961,  0.8615, -0.1497,  0.1669],\n",
      "         [-0.6429, -0.4948, -0.8536, -0.3695, -1.8177],\n",
      "         [-0.0750, -1.0071,  0.0934,  0.3871, -0.7766],\n",
      "         [-0.1049,  1.1328,  0.0172,  0.1523,  0.6585]],\n",
      "\n",
      "        [[ 0.4056, -0.7619, -0.8475,  0.5746, -0.1849],\n",
      "         [ 0.1131, -1.2611,  2.0405,  0.3159, -0.7189],\n",
      "         [-1.1022, -0.2296,  1.8284, -0.1389, -0.8939],\n",
      "         [ 1.2103,  0.1380,  0.2264,  0.2601, -0.4355]],\n",
      "\n",
      "        [[-0.2069,  0.1565, -1.6026,  1.5190, -1.1988],\n",
      "         [-1.2653,  0.0067,  0.6559,  0.0335, -0.5123],\n",
      "         [-0.7575,  1.6062,  0.6257,  1.4445, -1.4264],\n",
      "         [ 3.0929, -0.0182,  0.5986, -0.2219, -0.8094]],\n",
      "\n",
      "        [[ 0.1085, -0.9029, -0.0351,  0.7300,  0.4722],\n",
      "         [-0.2666, -0.4867, -0.3248, -0.5056,  0.4175],\n",
      "         [ 1.4615, -0.9728, -0.1542, -0.2300,  1.0143],\n",
      "         [ 0.2504, -0.8475, -0.3151, -0.0111,  2.1076]]])\n",
      "torch.Size([8, 5])\n",
      "tensor([[ 0.0556,  0.7931,  0.2027, -1.1361,  1.4996],\n",
      "        [ 0.0234,  2.2345,  0.0224,  0.4388, -0.4750],\n",
      "        [-0.4080, -1.2915, -0.4471, -1.7200, -0.9816],\n",
      "        [-0.4262, -2.2725, -1.3849,  0.8259,  0.2521],\n",
      "        [ 0.4162, -1.7961,  0.8615, -0.1497,  0.1669],\n",
      "        [ 0.4056, -0.7619, -0.8475,  0.5746, -0.1849],\n",
      "        [-0.2069,  0.1565, -1.6026,  1.5190, -1.1988],\n",
      "        [ 0.1085, -0.9029, -0.0351,  0.7300,  0.4722]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input = torch.randn(8, 4, 5)\n",
    "print(input.shape)\n",
    "print(input)\n",
    "logits = input[:, 0, :]\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d32bfade-48b7-44bc-bd09-5fd6f01a18af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 65])\n",
      "tensor([[[ 2.3839e+00,  2.2380e-01, -7.4795e-01, -9.6642e-01, -1.2405e-01,\n",
      "           1.5229e+00, -1.1294e+00,  9.5270e-01, -8.4379e-01,  1.7417e-01,\n",
      "          -1.5384e+00,  1.6064e+00, -5.6547e-01, -6.2347e-02, -5.8367e-01,\n",
      "          -1.9701e-01, -8.6588e-01,  7.1284e-01, -6.5321e-01,  1.0467e+00,\n",
      "           1.6062e-01,  2.6254e-01,  1.9448e-01,  8.8856e-01, -1.8510e+00,\n",
      "          -9.6507e-01,  1.1852e+00, -1.3623e+00, -1.1595e-03, -6.1612e-01,\n",
      "           4.1488e-01,  8.3554e-02, -2.0600e+00,  1.4339e+00, -1.4375e-01,\n",
      "          -9.0445e-01, -1.9722e-01, -1.5797e+00,  6.7009e-01, -1.6732e-02,\n",
      "           6.3933e-01,  1.3744e+00, -8.5839e-01, -9.8788e-01, -1.2302e+00,\n",
      "          -2.4145e+00, -2.6937e+00,  3.5657e-01,  4.2258e-01,  3.4872e-01,\n",
      "          -7.3164e-01, -6.4600e-02,  1.9877e-01,  8.2799e-01,  1.4397e+00,\n",
      "          -1.0195e+00, -1.6995e+00,  7.4717e-02,  8.2202e-01,  8.7804e-01,\n",
      "          -1.0397e-01,  6.0437e-01, -1.0304e+00,  1.8374e+00,  3.8428e-01]]])\n",
      "torch.Size([1, 65])\n",
      "tensor([[ 2.3839e+00,  2.2380e-01, -7.4795e-01, -9.6642e-01, -1.2405e-01,\n",
      "          1.5229e+00, -1.1294e+00,  9.5270e-01, -8.4379e-01,  1.7417e-01,\n",
      "         -1.5384e+00,  1.6064e+00, -5.6547e-01, -6.2347e-02, -5.8367e-01,\n",
      "         -1.9701e-01, -8.6588e-01,  7.1284e-01, -6.5321e-01,  1.0467e+00,\n",
      "          1.6062e-01,  2.6254e-01,  1.9448e-01,  8.8856e-01, -1.8510e+00,\n",
      "         -9.6507e-01,  1.1852e+00, -1.3623e+00, -1.1595e-03, -6.1612e-01,\n",
      "          4.1488e-01,  8.3554e-02, -2.0600e+00,  1.4339e+00, -1.4375e-01,\n",
      "         -9.0445e-01, -1.9722e-01, -1.5797e+00,  6.7009e-01, -1.6732e-02,\n",
      "          6.3933e-01,  1.3744e+00, -8.5839e-01, -9.8788e-01, -1.2302e+00,\n",
      "         -2.4145e+00, -2.6937e+00,  3.5657e-01,  4.2258e-01,  3.4872e-01,\n",
      "         -7.3164e-01, -6.4600e-02,  1.9877e-01,  8.2799e-01,  1.4397e+00,\n",
      "         -1.0195e+00, -1.6995e+00,  7.4717e-02,  8.2202e-01,  8.7804e-01,\n",
      "         -1.0397e-01,  6.0437e-01, -1.0304e+00,  1.8374e+00,  3.8428e-01]])\n",
      "tensor([[0.1101, 0.0127, 0.0048, 0.0039, 0.0090, 0.0466, 0.0033, 0.0263, 0.0044,\n",
      "         0.0121, 0.0022, 0.0506, 0.0058, 0.0095, 0.0057, 0.0083, 0.0043, 0.0207,\n",
      "         0.0053, 0.0289, 0.0119, 0.0132, 0.0123, 0.0247, 0.0016, 0.0039, 0.0332,\n",
      "         0.0026, 0.0101, 0.0055, 0.0154, 0.0110, 0.0013, 0.0426, 0.0088, 0.0041,\n",
      "         0.0083, 0.0021, 0.0198, 0.0100, 0.0192, 0.0401, 0.0043, 0.0038, 0.0030,\n",
      "         0.0009, 0.0007, 0.0145, 0.0155, 0.0144, 0.0049, 0.0095, 0.0124, 0.0232,\n",
      "         0.0428, 0.0037, 0.0019, 0.0109, 0.0231, 0.0244, 0.0091, 0.0186, 0.0036,\n",
      "         0.0638, 0.0149]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 65)\n",
    "print(input.shape)\n",
    "print(input)\n",
    "logits = input[:, -1, :]\n",
    "print(logits.shape)\n",
    "print(logits)\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772b4964-abf9-4621-b371-3fb673dba4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1101, 0.0127, 0.0048, 0.0039, 0.0090, 0.0466, 0.0033, 0.0263, 0.0044,\n",
      "         0.0121, 0.0022, 0.0506, 0.0058, 0.0095, 0.0057, 0.0083, 0.0043, 0.0207,\n",
      "         0.0053, 0.0289, 0.0119, 0.0132, 0.0123, 0.0247, 0.0016, 0.0039, 0.0332,\n",
      "         0.0026, 0.0101, 0.0055, 0.0154, 0.0110, 0.0013, 0.0426, 0.0088, 0.0041,\n",
      "         0.0083, 0.0021, 0.0198, 0.0100, 0.0192, 0.0401, 0.0043, 0.0038, 0.0030,\n",
      "         0.0009, 0.0007, 0.0145, 0.0155, 0.0144, 0.0049, 0.0095, 0.0124, 0.0232,\n",
      "         0.0428, 0.0037, 0.0019, 0.0109, 0.0231, 0.0244, 0.0091, 0.0186, 0.0036,\n",
      "         0.0638, 0.0149]])\n",
      "tensor([[22]])\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(logits, dim=-1)\n",
    "print(probs)\n",
    "idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "print(idx_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8b03c-f3d4-41da-8037-ed6f1483f336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zklearn",
   "language": "python",
   "name": "zklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
